#!/usr/bin/env python3
import logging
from typing import Dict, Any, Optional
from datetime import datetime
import json

from config_manager import config

logger = logging.getLogger(__name__)

class ComplianceManager:
    """Manages compliance requirements for OnlyFans platform"""
    
    def __init__(self):
        self.manual_send_required = config.is_manual_send_required()
        self.ai_disclosure_required = config.get('compliance_settings', 'ai_disclosure', default=False)
        
    def validate_message_generation(self, fan_id: str, message: str) -> Dict[str, Any]:
        """Validate message generation compliance"""
        validation_result = {
            "compliant": True,
            "warnings": [],
            "requirements": [],
            "timestamp": datetime.now().isoformat()
        }
        
        # Check manual send requirement
        if self.manual_send_required:
            validation_result["requirements"].append({
                "type": "manual_send",
                "description": "This message must be reviewed and sent manually",
                "action_required": "Copy message and send through OnlyFans interface"
            })
        
        # Check AI disclosure requirement
        if self.ai_disclosure_required and "AI" not in message.upper():
            validation_result["warnings"].append({
                "type": "ai_disclosure",
                "description": "Consider adding AI disclosure if required by platform policy",
                "suggestion": "Add disclaimer that content is AI-assisted"
            })
        
        # Content safety checks
        safety_checks = self._check_content_safety(message)
        if safety_checks:
            validation_result["warnings"].extend(safety_checks)
        
        # Platform policy compliance
        policy_checks = self._check_platform_policies(message)
        if policy_checks:
            validation_result["warnings"].extend(policy_checks)
        
        # Set compliance status
        validation_result["compliant"] = len([w for w in validation_result["warnings"] if w.get("severity") == "critical"]) == 0
        
        return validation_result
    
    def _check_content_safety(self, message: str) -> list:
        """Check for content safety issues"""
        warnings = []
        
        # Check for automated language
        automated_phrases = [
            "automatically generated", "auto-reply", "automated response",
            "bot message", "generated by ai", "artificial intelligence"
        ]
        
        message_lower = message.lower()
        for phrase in automated_phrases:
            if phrase in message_lower:
                warnings.append({
                    "type": "automated_language",
                    "description": f"Message contains automated language: '{phrase}'",
                    "severity": "medium",
                    "suggestion": "Remove or rephrase automated language"
                })
        
        # Check message length
        if len(message) > config.get('performance_settings', 'max_message_length', default=1000):
            warnings.append({
                "type": "message_length",
                "description": "Message exceeds recommended length",
                "severity": "low",
                "suggestion": "Consider shortening the message for better engagement"
            })
        
        return warnings
    
    def _check_platform_policies(self, message: str) -> list:
        """Check against OnlyFans platform policies"""
        warnings = []
        
        # Check for spam indicators
        spam_indicators = ["!!!", "URGENT", "LIMITED TIME", "ACT NOW"]
        message_upper = message.upper()
        
        spam_count = sum(1 for indicator in spam_indicators if indicator in message_upper)
        if spam_count > 1:
            warnings.append({
                "type": "spam_indicators",
                "description": "Message contains multiple spam indicators",
                "severity": "medium",
                "suggestion": "Reduce use of urgent/promotional language"
            })
        
        # Check for excessive emojis
        emoji_count = sum(1 for char in message if ord(char) > 127)
        if emoji_count > 10:
            warnings.append({
                "type": "excessive_emojis",
                "description": "Message contains excessive emojis",
                "severity": "low",
                "suggestion": "Reduce emoji usage for better readability"
            })
        
        return warnings
    
    def log_compliance_check(self, fan_id: str, validation_result: Dict[str, Any]):
        """Log compliance check for audit purposes"""
        log_entry = {
            "fan_id": fan_id,
            "timestamp": validation_result["timestamp"],
            "compliant": validation_result["compliant"],
            "warnings_count": len(validation_result["warnings"]),
            "requirements_count": len(validation_result["requirements"])
        }
        
        if validation_result["compliant"]:
            logger.info(f"Compliance check passed for fan {fan_id}", extra=log_entry)
        else:
            logger.warning(f"Compliance issues detected for fan {fan_id}", extra=log_entry)
    
    def get_compliance_summary(self) -> Dict[str, Any]:
        """Get current compliance configuration summary"""
        return {
            "manual_send_required": self.manual_send_required,
            "ai_disclosure_required": self.ai_disclosure_required,
            "platform": "OnlyFans",
            "last_updated": datetime.now().isoformat(),
            "compliance_version": "1.0"
        }
    
    def format_message_for_manual_send(self, message: str, validation_result: Dict[str, Any]) -> str:
        """Format message with compliance information for manual sending"""
        output = f"=== COMPLIANCE-CHECKED MESSAGE ===\n\n"
        output += f"Message: {message}\n\n"
        
        if validation_result["requirements"]:
            output += "REQUIREMENTS:\n"
            for req in validation_result["requirements"]:
                output += f"- {req['description']}\n"
            output += "\n"
        
        if validation_result["warnings"]:
            output += "WARNINGS:\n"
            for warning in validation_result["warnings"]:
                output += f"- {warning['description']}\n"
                if "suggestion" in warning:
                    output += f"  Suggestion: {warning['suggestion']}\n"
            output += "\n"
        
        output += f"Compliance Status: {'✅ COMPLIANT' if validation_result['compliant'] else '⚠️  REVIEW REQUIRED'}\n"
        output += f"Generated: {validation_result['timestamp']}\n"
        output += "\n=== END COMPLIANCE CHECK ===\n"
        
        return output

# Global compliance manager instance
compliance = ComplianceManager()