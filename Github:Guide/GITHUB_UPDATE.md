# ğŸš€ Marketing Automation System - GitHub Update

## ğŸ“‹ Overview

This update adds a comprehensive marketing automation system to the OFM platform with AI-powered content planning, social media intelligence, and automated scheduling.

## ğŸ¯ Key Features Added

### 1. Content Planning & Scheduling
- **Weekly content calendar** generation with optimal posting times
- **Multi-platform support**: Instagram, TikTok, Twitter/X, Reddit  
- **Content repurposing**: Turn 3 pieces of content into 9+ posts
- **Approval workflows** with status tracking
- **Temporal-based scheduling** for reliable execution

### 2. Social Media Intelligence
- **Profile scraping** from top creators across platforms
- **Competitor analysis** with follower tracking
- **Automatic categorization** (fitness, lifestyle, adult content, etc.)
- **Performance metrics** collection

### 3. AI-Powered Strategy
- **ML clustering** for creator categorization
- **Personalized recommendations** based on profile analysis
- **Hashtag suggestions** by category
- **Optimal posting times** based on audience type

### 4. Automation Pipeline
- **Scheduled workflows** (daily/weekly scraping)
- **Automatic model retraining** as new data arrives
- **Prometheus metrics** for monitoring
- **Feature flags** for safe rollouts

## ğŸ“ New Files Structure

```
marketing/backend/api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ContentPlan.ts          # Content planning data model
â”‚   â”‚   â””â”€â”€ TopProfile.ts           # Scraped profiles model
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ contentPlanning.ts      # Content plan generation logic
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ types.ts                # Scraper interfaces
â”‚   â”‚   â”œâ”€â”€ instagram.ts            # Instagram scraper
â”‚   â”‚   â”œâ”€â”€ tiktok.ts              # TikTok scraper
â”‚   â”‚   â”œâ”€â”€ twitter.ts             # Twitter/X scraper
â”‚   â”‚   â”œâ”€â”€ reddit.ts              # Reddit scraper
â”‚   â”‚   â””â”€â”€ index.ts               # Scraper orchestration
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ dataPrep.ts            # ML data preparation
â”‚   â”‚   â”œâ”€â”€ textVectorizer.ts      # TF-IDF & K-Means implementation
â”‚   â”‚   â””â”€â”€ contentCategorizer.ts  # Model training & inference
â”‚   â”œâ”€â”€ temporal/
â”‚   â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”‚   â”œâ”€â”€ contentPublishing.ts # Content publishing workflow
â”‚   â”‚   â”‚   â””â”€â”€ scrapeAndTrain.ts   # Scraping & training workflow
â”‚   â”‚   â”œâ”€â”€ activities/
â”‚   â”‚   â”‚   â”œâ”€â”€ contentPublishing.ts # Publishing activities
â”‚   â”‚   â”‚   â””â”€â”€ scrapeAndTrain.ts   # Scraping & training activities
â”‚   â”‚   â”œâ”€â”€ schedules.ts            # Scheduled workflow management
â”‚   â”‚   â””â”€â”€ marketingClient.ts      # Temporal client wrapper
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ contentPlan.ts         # Content planning endpoints
â”‚   â”‚   â”œâ”€â”€ scraper.ts             # Scraper control endpoints
â”‚   â”‚   â”œâ”€â”€ ml.ts                  # ML/AI endpoints
â”‚   â”‚   â””â”€â”€ automation.ts          # Automation control endpoints
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ metrics.ts             # Prometheus metrics
â”‚   â””â”€â”€ index.ts                   # Updated main server file
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ 20240112_create_content_plans.js
â”‚   â””â”€â”€ 20240112_create_top_profiles.js
â”œâ”€â”€ package.json                    # Dependencies & scripts
â”œâ”€â”€ tsconfig.json                  # TypeScript configuration
â”œâ”€â”€ .env.example                   # Environment variables template
â””â”€â”€ README.md                      # Documentation
```

## ğŸ”§ Installation & Setup

### 1. Install Dependencies
```bash
cd marketing/backend/api
npm install
```

### 2. Environment Configuration
```bash
cp env.example .env
# Edit .env with your settings:
# - DATABASE_URL
# - TEMPORAL_ADDRESS
# - JWT_SECRET
# - ENABLE_AUTOMATION=true
# - SCRAPER_CRON="0 3 * * *"
```

### 3. Database Setup
```bash
# Run migrations
npm run migrate

# Optional: Seed with test data
npm run seed
```

### 4. Start Services
```bash
# Terminal 1: Start Temporal worker
npm run worker

# Terminal 2: Start API server
npm run dev
```

## ğŸ”Œ API Endpoints

### Content Planning
```bash
# Generate weekly content plan
POST /api/content-plan/generate
{
  "originalsPerWeek": 3,
  "platforms": ["instagram", "tiktok", "twitter"],
  "requireApproval": true
}

# Get content plan
GET /api/content-plan?week=2024-W03

# Approve content
PUT /api/content-plan/:id/approve
```

### Profile Scraping
```bash
# Trigger scraping
POST /api/scraper/scrape-profiles
{
  "platforms": {
    "instagram": ["username1", "username2"],
    "tiktok": ["creator1", "creator2"]
  }
}

# Get scraped profiles
GET /api/scraper/top-profiles?platform=instagram&minFollowers=10000
```

### AI/ML Operations
```bash
# Train model
POST /api/ml/train

# Get content strategy
POST /api/ml/suggest-strategy
{
  "bio": "Fitness coach and nutrition expert..."
}
```

### Automation Control
```bash
# Manual trigger
POST /api/automation/scrape-and-train

# Check schedule status
GET /api/automation/schedule/status

# Pause/Resume automation
POST /api/automation/schedule/pause
POST /api/automation/schedule/resume
```

## ğŸ“Š Monitoring

### Prometheus Metrics
Access metrics at `GET /metrics`:

- `ofm_scraper_runs_total` - Total scraper executions
- `ofm_scraper_profiles_scraped` - Profiles scraped by platform
- `ofm_model_training_runs_total` - Model training executions
- `ofm_content_plans_created` - Content plans generated

### Health Check
```bash
GET /health
```

## ğŸ›¡ï¸ Security & Safety

1. **Rate Limiting**: Built-in delays between scraping requests
2. **Idempotency**: Duplicate workflow prevention via Temporal
3. **Feature Flags**: `ENABLE_AUTOMATION` environment variable
4. **Input Validation**: All endpoints validate inputs
5. **Error Handling**: Comprehensive error tracking and recovery

## ğŸš¦ Configuration Options

### Environment Variables
- `ENABLE_AUTOMATION` - Enable/disable scheduled workflows
- `SCRAPER_CRON` - Cron expression for automation (default: "0 3 * * *")
- `SCRAPER_PROFILE_LIMITS` - JSON limits per platform
- `TWITTER_BEARER_TOKEN` - Optional Twitter API access

### Customization Points
1. **Target Profiles**: Edit `src/scraper/index.ts` â†’ `getTargetProfiles()`
2. **Categories**: Modify `CATEGORY_KEYWORDS` in `contentCategorizer.ts`
3. **Posting Times**: Update `OPTIMAL_POSTING_TIMES` in `contentPlanning.ts`

## ğŸ§ª Testing

```bash
# Run tests
npm test

# Type checking
npm run typecheck

# Linting
npm run lint
```

## ğŸ“ˆ Performance Considerations

- **Scraping**: Limited to 1-2 second delays between requests
- **ML Training**: Handles up to 10,000 profiles efficiently
- **Content Planning**: Generates weekly plans in <1 second
- **Database**: Indexes on key query fields

## ğŸ”„ Migration Guide

For existing installations:

1. Run database migrations
2. Configure environment variables
3. Test with `dryRun: true` mode
4. Enable automation gradually

## ğŸ› Known Issues & TODOs

- [ ] Twitter scraping requires API token (limited without)
- [ ] Add support for YouTube and LinkedIn
- [ ] Implement content performance tracking
- [ ] Add A/B testing for posting times
- [ ] Create admin dashboard UI

## ğŸ“ License

Proprietary - OFM Platform

---

## ğŸ’¡ Next Steps

1. **Review** the implementation and adjust configuration
2. **Test** with a small set of profiles first
3. **Monitor** metrics and logs during initial runs
4. **Scale** by adding more profiles and platforms
5. **Iterate** on ML model with real performance data

For questions or improvements, please open an issue or submit a PR!